"Domain","Master","Topic","Control Statement","ISO42001","ISO27001","ISO27701","EU AI ACT","NIST RMF","SOC2"
"Governance & Leadership","GL-1","Executive Commitment and Accountability","The organisation's executive leadership shall establish, document, and maintain formal accountability for AI governance through approved policies that align with organisational objectives and values. These policies shall be reviewed at planned intervals by executive leadership to ensure continued effectiveness and relevance. Executive leadership shall demonstrate active engagement in AI risk decisions and maintain ultimate accountability for the organisation's AI systems.","4.1
5.1
5.2
9.3
A.2.2
A.2.3
A.2.4","5.1
5.2
9.3
A.5.1
A.5.2
","6.1.1
6.1.2","4,1","Govern 1.1
Govern 2.3
Govern 3.1","CC.1.1
CC.1.2
CC.1.3
CC.1.4
CC.1.5
CC.5.3"
"Governance & Leadership","GL-2","Roles, Responsibilities & Resources","The organisation shall define, document, and maintain clear roles and responsibilities for AI governance, ensuring appropriate segregation of duties and allocation of resources. These roles shall be staffed with competent individuals who understand their responsibilities for AI system development, deployment, and oversight. The organisation shall maintain documentation of required resources, including personnel competencies, tools, and infrastructure needed for effective AI governance.","5.3
7.1-7.3
A.3.2
A.4.2
","5.3
7.1-7.3
A.6.1
A.6.2
A.7.2
","6.2.1
6.2.2
7.2.2
9.2.3","22.1
22.2
26.3",,"CC.1.3
CC.1.4"
"Governance & Leadership","GL-3","Strategic Alignment & Objectives","The organisation shall document clear objectives for the responsible development and use of AI systems, ensuring alignment between business goals, ethical principles, and regulatory requirements. These objectives shall be integrated into organisational practices and regularly reviewed to maintain effectiveness. The organisation shall foster an environment that promotes critical thinking and safety-first approaches to AI development and deployment.","4.1-4.4
5.2
6.2-6.3
A.2.2-A.2.4
A.6.1.2
A.9.3
A.9.4","4.1-4.4
6.2-6.3","A.7.2.1
A.7.2.2
B.8.2.2",,"Map 1.3
Map 1.4
Govern 1.1
Govern 1.2
Govern 4.1
Govern 3.1",
"Risk Management","RM-1","Risk Management Framework and Governance","The organisation shall establish, document, and maintain a comprehensive risk management system covering the entire AI lifecycle. This system shall define clear roles, responsibilities, and processes for identifying, assessing, treating, and monitoring AI-related risks. The framework shall incorporate regular reviews by executive leadership and ensure risk management activities align with organisational risk tolerance. Risk management processes shall be transparent, documented, and appropriately resourced to maintain effectiveness.","6.1
","6,1","12.2.1
A.7.2.5
A.7.2.8
B.8.2.6","9.1
9.2","Govern 1.3
Govern 1.4
Govern 1.5
Map 1.5","CC3.1"
"Risk Management","RM-2","Risk Identification and Impact Assessment","The organisation shall conduct and document comprehensive impact assessments for AI systems, evaluating potential effects on individuals, groups, and society throughout the system lifecycle. These assessments shall consider fundamental rights, safety implications, environmental impacts, and effects on vulnerable populations. The organisation shall maintain a systematic approach to identifying both existing and emerging risks, including those from third-party components and systems.","6.1.1-6.1.2
6.1.4
8.4
A.5.2
A.5.3
A.5.4
A.5.5
","6.1.2","A.7.2.5
A.7.3.10
A.7.4.4","9.9
27.1","Map 1.1 
Map 3.1
Map 3.2
Measure 2.6
Measure 2.7
Measure 2.8
Measure 2.10
Measure 2.12","CC3.2"
"Risk Management","RM-3","Risk Treatment and Control Implementation","The organisation shall implement appropriate technical and organisational measures to address identified risks, ensuring controls are proportionate to risk levels and organisational risk tolerance. Risk treatment strategies shall be documented and prioritised based on impact and likelihood, with clear accountability for implementation. The organisation shall maintain specific protocols for high-risk AI systems, including quality management systems and compliance verification processes.","6.1.3","6.1.3","A.7.4.1
A.7.4.2
A.7.4.4
A.7.4.5","8.1
8.2
17.1
9.3
9.4
9.5","Manage 1.2
Manage 1.3
Manage 1.4","CC5.1 
CC9.1"
"Risk Management","RM-4","Risk Monitoring and Response","The organisation shall implement continuous monitoring processes to track the effectiveness of risk controls and identify emerging risks throughout the AI lifecycle. This shall include mechanisms for detecting and responding to previously unknown risks, regular evaluation of third-party risk exposure, and processes for incident response and recovery. The organisation shall maintain documentation of monitoring activities and ensure appropriate escalation paths for risk-related issues.","6.1.3
8.1-8.3","6.1.3
8.1-8.3
","A.7.4.3
A.7.4.9
B.8.2.4
B.8.2.5
B.8.4.3","9,6","Measure 3.1
Measure 3.2
Manage 2.1
Manage 2.2
Manage 2.3
Manage 3.1
Govern 6.1
Govern 6.2","CC3.4
CC9.2"
"Regulatory Operations","RO-1","Regulatory Compliance Framework","The organisation shall establish, document, and maintain a comprehensive framework for ensuring compliance with applicable AI regulations and standards. This framework shall include processes for identifying relevant requirements, assessing applicability, implementing necessary controls, and verifying ongoing compliance. The organisation shall maintain systematic processes for tracking and implementing new regulatory requirements, conducting conformity assessments, maintaining necessary certifications, and ensuring timely renewal of compliance documentation. Special attention shall be given to high-risk AI system requirements and prohibited practices. The organisation shall implement processes to track changes that may affect compliance status and maintain evidence of continued conformity with legal obligations",,"A.18.1","18.2.1
A.7.2.1-A.7.2.4
B.8.2.1-B.8.2.2
B.8.2.4-B.8.2.5","5.1
5.2
6.1-6.4
8.1-8.2
40.1
41.1
42.1
43.1-43.4
44.2-44.3
47.1-47.4
49.1-49.3
","Govern 1.1
Map 4.1","CC1.5"
"Regulatory Operations","RO-2","Transparency, Disclosure and Reporting","The organisation shall implement mechanisms to ensure appropriate transparency regarding AI systems, including clear notification of AI use, disclosure of automated decision-making, and communication of significant system changes. The organisation shall establish and maintain processes for reporting incidents, safety issues, and non-compliance to relevant authorities and affected stakeholders. This shall include clear procedures for incident detection, assessment, notification timelines, and follow-up actions.","A.8.3
A.8.5","A.6.3","6.2.3
A.7.3.2-A.7.3.3
A.7.3.8-A.7.3.9
A.7.5.3-A.7.5.4
B.8.5.3-B.8.5.6","50.1-50.5
86.1-86.3
20.1
20.2
60.7
60.8","Govern 6.1
Map 4.1","CC2.3
P1.1
P1.2
P1.3"
"Regulatory Operations","RO-3","Record-Keeping","The organisation shall maintain comprehensive documentation and records demonstrating compliance with AI regulatory requirements. This shall include technical documentation, conformity assessments, impact analyses, test results, and evidence of ongoing monitoring. The organisation shall establish retention periods aligned with regulatory requirements, implement secure storage systems, and ensure documentation remains accessible to authorised parties throughout required retention periods.",,"A.7.2","8.2.3
A.7.2.8
A.7.3.1
A.7.4.3
A.7.4.6-A.7.4.8
B.8.2.6
B.8.4.1-B.8.4.2","11.1
11.3
18.1
19.1
19.2
71.2
71.3","Map 4.1
Measure 2.12","P3.1
P3.2
P3.3"
"Regulatory Operations","RO-4","Post-Market Monitoring","The organisation shall implement comprehensive post-market monitoring systems for deployed AI systems, including mechanisms for tracking performance, identifying issues, and implementing corrective actions. This shall include processes for reporting incidents to relevant authorities, maintaining required documentation, and conducting periodic reviews of system performance. The organisation shall ensure appropriate escalation paths exist for identified issues and maintain clear procedures for implementing necessary corrective actions.","A.8.3",,"6.2.3
A.7.3.6-A.7.3.7
A.7.3.10
A.7.4.3
B.8.3.1
B.8.5.7-B.8.5.8","72.1-72.4
79.4
80.4-80.5","Govern 6.1
Measure 2.12","CC1.5"
"System, Data and Model Lifecycle","LC-1","Data Quality and Governance","The organisation shall establish and maintain comprehensive data governance processes ensuring high-quality data throughout the AI system lifecycle. This shall include documented requirements and procedures for data collection, processing, and validation, ensuring datasets are relevant, representative, and statistically suitable for their intended purpose. The organisation shall implement processes for bias detection and mitigation, maintain clear data provenance records, and ensure data reflects the specific geographical, behavioural, and functional settings where AI systems will be used.","A.7.2-A.7.6",,"A.7.4.1-A.7.4.2
A.7.4.6-A.7.4.8
B.8.4.1-B.8.4.2","10.1-10.6","Map 2.1",
"System, Data and Model Lifecycle","LC-2","System Development and Lifecycle Management","The organisation shall define, document, and maintain processes for responsible AI system development across the entire lifecycle, from requirements specification through deployment and eventual decommissioning. The organisation shall maintain clear records of system objectives, technical implementation decisions, and operational constraints throughout development and deployment phases.","A.6.1.2-A.6.1.3
A.6.2.2-A.6.2.3
A.6.2.5",,"A.7.4.1-A.7.4.2
A.7.4.5-A.7.4.8
B.8.4.1-B.8.4.2",,"Map 1.6
Govern 1.7","CC8.1
CC8.2"
"System, Data and Model Lifecycle","LC-3","Resource Management and Infrastructure","The organisation shall document and maintain inventories of all resources required for AI system development and operation, including data resources, tooling, computing infrastructure, and human competencies. This shall include clear allocation of responsibilities, documentation of system dependencies, and maintenance of resource specifications throughout the system lifecycle.","A.4.3
A.4.5
A.4.6
A.10.2","A.8.1
A.8.2","A.7.2.6
A.7.2.7
B.8.5.6",,"Govern 1.6",
"System, Data and Model Lifecycle","LC-4","Technical Documentation","The organisation shall maintain comprehensive technical documentation demonstrating compliance throughout the AI system lifecycle. This shall include system characteristics, design specifications, validation results, and operational logs. The organisation shall implement automated logging mechanisms to capture system events, maintain documentation for required retention periods, and ensure documentation remains accessible to relevant stakeholders.","7.5.1-7.5.3
A.6.2.7
A.6.2.8","7.5.1-7.5.3","A.7.2.8
A.7.5.3
A.7.5.4
B.8.2.6
B.8.5.3","11.1-11.3
12.1-12.3
18.1","Map 2.2
Map 3.3",
"System, Data and Model Lifecycle","LC-5","Change Management & Version Control","The organisation shall establish and maintain comprehensive processes for managing changes to AI systems throughout their lifecycle. This shall include documented procedures for proposing, evaluating, testing, and implementing changes to models, data, or system components. The organisation shall maintain detailed version control of all system elements, including models, datasets, and software components, with clear records of modifications and their rationale. Changes shall be tested and validated before deployment, with documentation updated to reflect current system state.","A.6.2.5","A.12.2","A.7.3.7
B.8.5.7
B.8.5.8","11,3","Map 2.1","CC8.1
CC8.2"
"Security","SE-1","Security Governance, Architecture and Engineering","The organisation shall establish and maintain a comprehensive security governance framework that encompasses security risk management, security policies, standards, and architectures that guide the implementation of security controls across the organisation. The organisation shall ensure continuous monitoring of control effectiveness, manages security incidents, and maintains business continuity capabilities while overseeing third-party security requirements.",,"A.5.1-A.5.2
A.6.1-A.6.2
A.6.5
A.7.1-A.7.4
A.12.1-A.12.3
A.17.1-A.17.2
A.18.1-A.18.2","14.2.1
14.2.2",,,"CC2.3
CC3.1
CC3.2
CC5.2
CC7.2
CC7.3
CC9.3"
"Security","SE-2","Identity & Access Management","The organisation shall implement and maintains comprehensive identity and access management controls governing authentication, authorisation, and access monitoring across all systems and applications. This includes the complete lifecycle of identity management from screening to provisioning through deprovisioning, ensuring appropriate access levels are maintained and regularly reviewed. The organisation shall implement strong authentication mechanisms and maintains detailed access logs for all critical systems.",,"A.9.1
A.9.2
A.9.3
A.9.4","9.2.1
9.2.2
9.2.4",,,"CC6.1
CC6.2
CC6.3"
"Security","SE-3","Software Security","The organisation shall ensure all software development and deployment activities follow secure development practices throughout the system development lifecycle. This includes implementing secure coding standards, conducting security testing, managing secure configurations, and maintaining robust change management procedures for all production systems. The organisation shall regularly assess applications for security vulnerabilities and maintain secure development environments.",,"A.14.1
A.14.2
A.12.2","14.2.1
14.2.2",,,"CC5.2
CC7.1"
"Security","SE-4","Data Security","The organisation shall protect data throughout its lifecycle using appropriate technical and procedural controls, including classification, encryption, and secure handling procedures. This encompasses structured and unstructured data across all storage locations and transmission paths. The organisation shall maintain comprehensive data protection mechanisms, including backup systems, encryption standards, and secure disposal procedures, while ensuring appropriate data classification and handling requirements are enforced.",,"A.8.1-A.8.7
A.10.1
A.10.2
A.12.4
A.12.5
A.14.3
","8.2.4
8.3.1
8.3.2
8.3.3
10.2.1
10.2.2
11.2.2",,,"CC6.4-CC6.7
C1.1
C1.2
P5.1-P5.4
P5.6"
"Security","SE-5","Network Security","The organisation shall implement and maintain comprehensive network security controls to protect against unauthorised access, ensure secure communications, and maintain the confidentiality and integrity of data in transit. This includes implementing secure network architectures, maintaining network monitoring capabilities, and ensuring appropriate network segmentation. The organisation shall regularly assess network security controls and maintain comprehensive network logging and monitoring capabilities.",,"A.13.1-A.13.3
A.12.4
A.12.6
A.10.1
A.10.2","13.2.1",,,"CC6.6
CC7.1
CC7.2"
"Security","SE-6","Physical Security","The organisation shall implement and maintain comprehensive physical security controls to protect information assets, including facilities, equipment, and supporting infrastructure from unauthorised access and environmental threats. This includes maintaining secure physical perimeters, implementing environmental controls, monitoring physical access, and ensuring appropriate protection for equipment and supporting infrastructure.",,"A.11.1
A.11.2
A.11.3
A.11.4
A.11.5","11.2.1",,,"CC6.1"
"Safe Responsible AI","RS-1","Human Oversight and Intervention","The organisation shall implement mechanisms for meaningful human oversight of AI systems, ensuring humans maintain appropriate control over AI decision-making. This includes clearly defined procedures for human monitoring, intervention capabilities, and authority to override AI systems when necessary. Personnel responsible for oversight must receive appropriate training and have sufficient competence and authority to fulfill their responsibilities effectively.","A.9.2
A.9.3
A.9.4","A.18.1.1 
A.18.2.2
A.6.1
A.6.2","7.2.2
7.2.5","14.1-14.5
26.2
4.1","Govern 3.2
Map 3.4
Map 3.5","CC1.1 
CC2.1"
"Safe Responsible AI","RS-2","Safety","The organisation shall establish and maintain processes to prevent AI systems from producing outputs that could cause harm to individuals, groups, or society. This includes comprehensive impact assessments, monitoring for potential harms, and implementation of safeguards to prevent prohibited uses or manipulative practices. The organisation must maintain documented evidence of harm prevention measures and regularly assess their effectiveness.","A.5.2
A.5.3
A.5.4
A.5.5","A.12.1","7.2.3
7.2.4","5.1
5.2
9.1-9.3","Map 1.1
Map 3.1
Map 3.2
Measure 3.1
Measure 3.2","CC4.1
CC5.1"
"Safe Responsible AI","RS-3","Robustness","The organisation shall ensure AI systems demonstrate consistent and reliable performance across their intended operating conditions, including edge cases and unexpected scenarios. Systems must be resilient against errors, adversarial attacks, and data quality issues. Regular testing and monitoring shall be conducted to verify robustness, with particular attention to system behavior under stress conditions or when encountering novel situations.","A.9.4","A.17.1
A.17.2","7.2.8","8.1
8.2
15.1
15.4
15.5","Map 2.1
Map 2.2
Measure 4.2
Measure 4.3","CC7.1
CC8.1"
"Safe Responsible AI","RS-4","Explainability and Interpretability","The organisation shall ensure AI systems' decisions and outputs can be appropriately explained and interpreted by relevant stakeholders. This includes maintaining comprehensive documentation of system behaviour, providing clear explanations of AI-driven decisions when required, and ensuring transparency about system capabilities and limitations. Methods for generating explanations must be appropriate to the context and audience.","A.5.3",,"7.2.1","50.2
50.3
50.4
50.5","Govern 4.2
Map 2.2
Map 2.3
Measure 2.8","CC2.2
CC2.3"
"Safe Responsible AI","RS-5","Fairness and Bias Management","The organisation shall implement processes to identify, assess, and mitigate unfair bias in AI systems throughout their lifecycle. This includes ensuring training data is representative and appropriate, regularly testing for disparate impact across protected characteristics, and maintaining documented evidence of fairness assessments and mitigation measures. The organisation must regularly validate that AI systems maintain fairness standards in operation.","A.5.4",,"7.2.6","5.1
26.4","Measure 2.11
 Govern 5.2
 Measure 2.2","CC1.3
CC5.3"
"Privacy","PR-1","Privacy by Design and Governance","The organisation shall implement privacy by design principles in all AI systems, ensuring privacy considerations are embedded from initial planning through system retirement. This includes establishing and maintaining comprehensive privacy policies, conducting privacy impact assessments, defining clear privacy roles and responsibilities, and integrating privacy requirements into project management processes. The organisation shall establish privacy governance structures, maintain documentation of privacy decisions, regularly review privacy controls for effectiveness, and ensure special categories of personal data are processed only when strictly necessary and with appropriate safeguards. Senior management shall demonstrate commitment to privacy through resource allocation and oversight of privacy initiatives.",,,"6.1.1
6.1.2
6.2.1-6.2.4
7.2.1-7.2.3
7.2.5
7.2.7
12.2.1
A.7.4.1-A.7.4.9
B.8.4","10.5
26.9
27.4",,"P1.1
P1.2
P1.3"
"Privacy","PR-2","Personal Data Management","The organisation shall implement operational processes for the responsible collection, use, storage, and disposal of personal data in AI systems. This includes maintaining data inventories, implementing data classification schemes, managing data retention schedules, and ensuring appropriate data handling throughout the information lifecycle. The organisation shall obtain and maintain records of consent for data processing, provide individuals with access to their data, implement processes for handling data subject requests, and ensure data quality standards are maintained. Clear procedures for data minimisation, purpose limitation, and secure disposal shall be established and followed.",,,"8.2.1-8.2.4
 8.3.1-8.3.3
A.7.2.1-A.7.2.8
A.7.3.1-A.7.3.10
7.4.5
A.7.5.1-A.7.5.4
B.8.2
B.8.3
B.8.4.2
B.8.5",,,"P2.1
P2.2
P3.1-P3.3
P4.1-P4.3"
"Privacy","PR-3","Privacy Compliance and Monitoring","The organisation shall establish processes to monitor compliance with privacy requirements, detect and respond to privacy incidents, and ensure continuous improvement of privacy controls. This includes conducting regular privacy audits, monitoring data processing activities, managing privacy incidents, ensuring supplier compliance with privacy requirements, and maintaining business continuity plans that address privacy considerations. The organisation shall implement privacy metrics, conduct regular assessments, comply with breach notification requirements, and demonstrate ongoing compliance with applicable privacy regulations through documented evidence.",,,"12.2.2
15.2.1
16.2.1
16.2.2
17.2.1
18.2.1
18.2.2
A.7.2.5-A.7.2.7
A.7.3.6
B.8.2.4
B.8.2.5",,,"P6.1
P6.2
P6.3
P6.4
P6.5"
"Privacy","PR-4","Privacy-Enhancing Technologies and Mechanisms","The organisation shall implement appropriate technical mechanisms and privacy-enhancing technologies in AI systems to protect personal data and ensure privacy by default. This includes implementing encryption for data at rest and in transit, role-based access control mechanisms, data minimisation techniques, anonymisation and pseudonymisation methods, and secure deletion capabilities. The organisation shall ensure these mechanisms are appropriate for the sensitivity of the data, regularly tested for effectiveness, and updated as privacy-enhancing technologies evolve. This includes how technical controls are documented, validated, and integrated into the system architecture to provide defense in depth for privacy protection.",,,"9.2.1-9.2.4
10.2.1-10.2.2
11.2.1-11.2.2
13.2.1
14.2.1-14.2.2
A.7.4.5
A.7.4.9
B.8.4.3",,,"P5.1
P5.2
P5.3
P5.4
P5.5
P5.6"
"Assurance and Audit","AA-1","Internal Assessment & Audit","The organisation shall establish and maintain comprehensive internal assessment and audit procedures for AI systems throughout their lifecycle. This includes documented verification of controls and validation of system behavior in both controlled and real-world conditions. Internal audits must evaluate compliance with organisational policies and procedures. Internal assessment and audit activities must cover normal operations, edge cases, and stress conditions. The organisation shall maintain evidence of all audit activities, findings, and remediation efforts.","9.1
9.2
9.3
A.6.2.4","9.1
9.2
9.3
A.18.2
","8.2.3
18.2.2
A.7.2.5
A.7.4.3","9.7-9.8
17.1-17.2
60.1-60.9
61.1
61.2","Map 2.3
 Measure 2.1
 Measure 2.3
 Measure 2.5","PI1.1
PI1.2
CC4.1"
"Assurance and Audit","AA-2","Independent Assessment and Certification","The organisation shall ensure regular independent assessments of AI systems are conducted and maintain necessary certifications. Independent assessors must have appropriate expertise and authority to evaluate compliance with regulatory requirements and performance standards. The organisation shall obtain and maintain required certifications, track certification status, and implement corrective actions when gaps are identified. Assessment and certification activities must be documented, including findings and evidence of remediation.","9.1
9.3
10.1
10.2","9.1
9.3
10.1
10.2
A.18.1
A.18.2
","7.2.1","20.1
22.3-22.4
40.1
43.1-43.4
44.2
44.3","Measure 1.3
 Measure 4.2
 Govern 4.3","CC4.2
CC3.1"
"Assurance and Audit","AA-3","Safety and Security Validation","The organisation shall conduct regular testing of AI system safety and security controls, including assessment of cybersecurity measures, resilience against attacks, and ability to fail safely. Testing must verify that systems operate within defined risk tolerances and maintain effectiveness of protective controls. Validation must include both automated testing and expert review of safety measures. The organisation shall maintain documentation of all safety and security assessments, including methodology, results, and remediation of identified issues.","9.1
9.3","9.1
9.3
A.18.1
A.18.2
","7.2.5","41.1-41.2
42.1-42.2","Measure 2.6
 Measure 2.7","CC7.1"
"Operational Monitoring","OM-1","System Performance Monitoring","The organisation shall implement continuous monitoring of AI system performance and behavior in production environments. This includes automated monitoring of key performance indicators, tracking of system outputs, detection of anomalies or degradation in performance, and validation that systems operate within defined parameters. The organisation must maintain documentation of monitoring results, performance trends, and actions taken to address identified issues. Monitoring activities shall be proportional to the system's risk level and complexity.","8.1-8.3
A.6.2.6","8.1-8.3
A.12.3
A.12.6
A.17.1
A.17.2

","12.2.2
A.7.4.3","26.5
72.1
72.2
72.3
72.4","Measure 1.2
Measure 2.4
Manage 2.2
Manage 2.4","CC4.1
CC4.2
A1.1
A1.2"
"Operational Monitoring","OM-2","Event Logging","The organisation shall maintain comprehensive logs of AI system events and operations throughout their lifecycle. Logging systems must capture relevant operational data including system usage, input data references, and verification of results. Logs must be retained for required retention periods, protected from unauthorised access or modification, and made available to authorities when required. The organisation shall ensure logging systems enable effective compliance verification and support incident investigations.","A.6.2.8","A.12.6
A.12.7","12.2.2","12.1-12.3
19.1-19.2
 21.2
26.6","Govern 4.3","CC7.2
CC7.3"
"Operational Monitoring","OM-3","Continuous Improvement","The organisation shall establish and maintain a systematic approach to continuous improvement of AI systems throughout their operational lifecycle. This includes implementing processes to gather and analyse performance data, user feedback, and operational metrics to identify opportunities for enhancement. The organisation shall maintain documented improvement plans that outline specific objectives, timelines, and success criteria. Regular reviews must be conducted to evaluate the effectiveness of improvements and identify new areas for optimisation. The organisation shall ensure that improvement initiatives are prioritised based on operational impact and risk considerations, with clear processes for implementing and validating changes.","9.1
10.1
10.2
A.10.4","9.1
10.1
10.2
A.18.2
A.15.2
A.12.6
A.18.1
","A.7.4.3
A.7.3.6","17.1
72.1
72.2
72.3
72.4","Manage 4.1
Manage 4.2","CC3.3
A1.3"
"Third Party & Supply Chain","TP-1","Third-Party Provider Responsibilities","The organisation shall establish clear accountability for AI systems when working with third parties, distributors, importers, or suppliers. This includes documenting responsibilities when AI systems are modified or repurposed, ensuring proper handover of obligations between parties, and maintaining evidence of agreed responsibilities. The organisation must obtain necessary information and technical access from third-party suppliers to ensure regulatory compliance, while respecting confidentiality and intellectual property rights.","A.10.2","A.15.1","15.2.1
A.7.2.6-A.7.2.7
B.8.5.6-B.8.5.8","25.1 
25.2
25.3
25.4","Map 4.1 
Govern 6.1","CC2.3"
"Third Party & Supply Chain","TP-2","Supplier Risk Management","The organisation shall implement comprehensive processes to identify, assess, manage, and monitor risks associated with third-party AI suppliers and service providers throughout the engagement lifecycle. This includes evaluating supplier capabilities during selection, establishing security and privacy requirements in supplier agreements, maintaining contingency plans for critical third-party dependencies, and implementing continuous monitoring of supplier performance and compliance. The organisation shall regularly assess supplier adherence to established requirements, including security standards, privacy requirements, and service level agreements. Performance monitoring must include collection and evaluation of feedback, documentation of monitoring results, and implementation of appropriate actions when issues are identified. Regular reviews of supplier risk assessments and performance metrics shall inform decisions about continuing or modifying supplier relationships. ","A.10.3","A.15.1
A.15.2","15.2.1
A.7.2.6
A.7.5.1-A.7.5.2
B.8.5.1-B.8.5.2","25,4","Govern 5.1
Manage 3.1
Govern 6.1
Govern 6.2","CC9.2"
"Transparency & Communication","CO-1","AI System Transparency","The organisation shall ensure AI systems are designed and operated with appropriate transparency, enabling users and affected individuals to understand when they are interacting with AI, how the AI system impacts them, and what the system's capabilities and limitations are. This includes clear marking of AI-generated content, disclosure of automated decision-making, and provision of comprehensive documentation about system performance and intended use. The organisation must maintain accessibility standards in all transparency communications, provide explanations of AI-driven decisions when required by law, and ensure instructions and documentation are clear and accessible to intended audiences.","7.4
A.6.2.7
A.8.2
A.9.3
A.9.4","7.4
A.6.4
","A.7.3.2
A.7.3.3
A.7.3.10
B.8.2.3
","13.1-13.3
15.3
50.1-50.5
86.1-86.3","Map 1.2
Measure 4.1","CC2.2"
"Transparency & Communication","CO-2","Stakeholder Engagement and Feedback","The organisation shall implement comprehensive stakeholder engagement processes to collect, evaluate, and respond to feedback about AI system impacts and performance. This includes establishing mechanisms for regular stakeholder consultation, incorporating feedback into system improvements, and maintaining documentation of stakeholder engagement activities. The organisation must consider diverse perspectives, ensure feedback processes are accessible to all affected communities, and demonstrate how stakeholder input influences system development and operation. Regular reporting to stakeholders about system performance, impacts, and improvements must be maintained.","A.3.3
A.8.3
A.8.5
A.10.4","4.2
A.6.4
","A.7.3.4
A.7.3.5
A.7.3.9","4.1
26.7
26.11","Govern 5.1
Govern 5.2
Map 5.2
Measure 3.3
Measure 4.3","CC2.2"
"Incident Management","IM-1","Incident Detection and Response","The organisation shall establish and maintain a comprehensive incident management process for AI systems. This process must include mechanisms for detecting incidents, assessing their severity, implementing immediate response measures, and conducting thorough investigations. The organisation shall maintain documented procedures for incident response, ensure adequate resources are available for incident handling, and verify that response teams have appropriate expertise. Response procedures must address both technical and privacy-related incidents, with specific provisions for high-risk AI systems.","A.8.4","A.16.1
A.12.7","16.2.1
A.7.3.7
B.8.5.4","73,6","Manage 4.3","CC7.4
P6.1
P6.2"
"Incident Management","IM-2","Incident Reporting and Notification","The organisation shall implement processes for timely reporting of serious incidents to relevant suppliers, customers, authorities, affected individuals, and other stakeholders as required by applicable regulations or internal policy. This includes maintaining clear notification timelines based on incident severity, ensuring completeness and accuracy of incident reports. The organisation must document all notifications and maintain evidence of compliance.","A.8.4","A.16.1
A.16.2","16.2.2
B.8.5.4
B.8.5.5","73.1-73.5
73.9
73.10","Manage 4.3","P6.3
P6.4"
"Incident Management","IM-3","Incident Analysis and Improvement","The organisation shall analyse incidents to identify root causes, assess the effectiveness of response measures, and implement improvements to prevent recurrence. This includes conducting post-incident reviews, documenting lessons learned, updating incident response procedures based on experience, and verifying the effectiveness of corrective actions. The organisation must maintain records of all incident analyses and resulting improvements.","A.8.4","A.16.3","16.2.1","73,6","Manage 4.3","P6.5"
